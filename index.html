<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Project Page</title>

<link rel="stylesheet" href="style.css" />

</head>
<body>

<nav>
    <ul>
        <li><a href="#title-section">Home</a></li>
        <li><a href="#overview">Overview</a></li>
        <li><a href="#team">Team</a></li>
        <li><a href="#publications">Publications</a></li>
        <li><a href="#videos">Videos</a></li>
        <li><a href="#github">GitHub</a></li> 
    </ul>
</nav>

<div class="spacer"></div>

<!-- HERO SECTION -->
<section id="title-section">
    <h1>CASPER++</h1>
    <p>Cognitive Architecture for Social Perception and Engagement in Robots for ethical and transparent collaboration</p>
</section>

<!-- OVERVIEW -->
<section id="overview" class="section">
    <h2>Project Overview</h2>
    <p>
        Social robotics has made major advances in recent decades and is approaching real-world deployment, where humans and robots will collaborate as teammates in shared tasks. 
        To function effectively in these environments, robots must be able to understand, interpret, and adapt to the social dynamics of human groups while acting in ways that are ethical, transparent, and trustworthy.
    </p>
    <p>
        This project aims to develop socially aware and ethically grounded robots capable of seamlessly integrating into cooperative teams composed of both humans and other robots. 
        The core contribution is the design of a cognitive architecture that enables social perception, intention understanding, and engagement in heterogeneous multi-agent systems. 
        By equipping robots with advanced models of social cognition, the project supports transparent collaboration, shared goal understanding, and ethical decision-making in complex team settings.
    </p>
    <p>
        The research focuses on heterogeneous multi-agent teams—systems involving at least three agents, including both humans and robots—working together toward a common goal. 
        Through this work, the project seeks to enhance trust, accountability, and ethical value in human–robot collaboration, paving the way for reliable and socially responsible robotic teammates in future real-world applications.
    </p>
</section>

<!-- TEAM -->
<section id="team" class="section">
    <h2>Team</h2>
    <!--<p>Meet the members of the project team:</p>-->

    <div class="team-grid">

        <div class="team-member">
            <img src="Fotos/Angelo.jpg" alt="Photo">
            <h3>Angelo Cangelosi</h3>
            <p><em>Principal Investigator </em></p>

            <div class="social-icons">
                <a href="https://www.linkedin.com/in/angelo-cangelosi-389b01b8/" target="_blank" class="icon">
                    <!-- LinkedIn SVG -->
                    <svg viewBox="0 0 24 24" class="svg-icon">
                        <path d="M4.98 3.5C4.98 4.88 3.86 6 2.5 6S0 4.88 0 3.5 1.12 1 2.5 1 4.98 2.12 4.98 3.5zM.5 23.5h4V7.98h-4V23.5zM8.48 7.98H12v2.11h.06c.49-.93 1.69-1.91 3.48-1.91 3.72 0 4.4 2.45 4.4 5.64v9.68h-4v-8.57c0-2.04-.04-4.66-2.84-4.66-2.84 0-3.28 2.22-3.28 4.51v8.72h-4V7.98z"/>
                    </svg>
                </a>

                <a href="mailto:angelo.cangelosi@manchester.ac.uk" class="icon">
                    <!-- Email SVG -->
                    <svg viewBox="0 0 24 24" class="svg-icon">
                        <path d="M12 13.5L0 6V4l12 7.5L24 4v2l-12 7.5z"/>
                        <path d="M0 8v12h24V8l-12 7.5z"/>
                    </svg>
                </a>
            </div>
        </div>

        <div class="team-member">
            <img src="Fotos/Samuele.jpeg" alt="Photo">
            <h3>Samuele Vinanzi</h3>
            <p><em>Advisor</em></p>

            <div class="social-icons">
                <a href="https://www.linkedin.com/in/samuelevinanzi/" target="_blank" class="icon">
                    <svg viewBox="0 0 24 24" class="svg-icon">
                        <path d="M4.98 3.5C4.98 4.88 3.86 6 2.5 6S0 4.88 0 3.5 1.12 1 2.5 1 4.98 2.12 4.98 3.5zM.5 23.5h4V7.98h-4V23.5zM8.48 7.98H12v2.11h.06c.49-.93 1.69-1.91 3.48-1.91 3.72 0 4.4 2.45 4.4 5.64v9.68h-4v-8.57c0-2.04-.04-4.66-2.84-4.66-2.84 0-3.28 2.22-3.28 4.51v8.72h-4V7.98z"/>
                    </svg>
                </a>

                <a href="mailto:s.vinanzi@shu.ac.uk" class="icon">
                    <svg viewBox="0 0 24 24" class="svg-icon">
                        <path d="M12 13.5L0 6V4l12 7.5L24 4v2l-12 7.5z"/>
                        <path d="M0 8v12h24V8l-12 7.5z"/>
                    </svg>
                </a>
            </div>
        </div>

        <div class="team-member">
            <img src="Fotos/Leticia.jpg" alt="Photo">
            <h3>Leticia Berto</h3>
            <p><em>Postdoctoral Researcher</em></p>

            <div class="social-icons">
                <a href="https://www.linkedin.com/in/leticiaberto/" target="_blank" class="icon">
                    <svg viewBox="0 0 24 24" class="svg-icon">
                        <path d="M4.98 3.5C4.98 4.88 3.86 6 2.5 6S0 4.88 0 3.5 1.12 1 2.5 1 4.98 2.12 4.98 3.5zM.5 23.5h4V7.98h-4V23.5zM8.48 7.98H12v2.11h.06c.49-.93 1.69-1.91 3.48-1.91 3.72 0 4.4 2.45 4.4 5.64v9.68h-4v-8.57c0-2.04-.04-4.66-2.84-4.66-2.84 0-3.28 2.22-3.28 4.51v8.72h-4V7.98z"/>
                    </svg>
                </a>

                <a href="mailto:leticia.berto@manchester.ac.uk" class="icon">
                    <svg viewBox="0 0 24 24" class="svg-icon">
                        <path d="M12 13.5L0 6V4l12 7.5L24 4v2l-12 7.5z"/>
                        <path d="M0 8v12h24V8l-12 7.5z"/>
                    </svg>
                </a>
            </div>
        </div>

    </div>
</section>

 <!-- PUBLICATIONS -->
<section id="publications" class="section">
    <h2>Publications</h2>

    <ul class="pub-list">
        <li>
            <strong>CASPER: Cognitive Architecture for Social Perception and Engagement in Robots.</strong><br>
            <em>Vinanzi, S., Cangelosi, A.</em><br>
            <em>International Journal of Social Robotics 17, 1979–1997 (2025).</em><br>
            <a href="https://doi.org/10.1007/s12369-024-01116-2" target="_blank">https://doi.org/10.1007/s12369-024-01116-2</a>
        </li>
    </ul>
</section>

<!-- VIDEOS -->
<section id="videos" class="section">
    <h2>Videos</h2>

    <div class="video-grid">

        <div class="video-item">
            <iframe 
                src="https://www.youtube.com/embed/dQw4w9WgXcQ" 
                title="Video 1"
                allowfullscreen>
            </iframe>
            <p class="caption">
                A human carries out the goal <b><em>Lunch</em> without expecting any assistance</b>. Tiago++ observes the situation, infers the human’s goal, and reasons about which tasks it could potentially support based on its own skills. 
                Despite this capability, the human completes all steps independently, as no collaboration is anticipated.
            </p>
        </div>

        <div class="video-item">
            <iframe 
                src="https://www.youtube.com/embed/ysz5S6PUM-U" 
                title="Video 2"
                allowfullscreen>
            </iframe>
            <p class="caption">
                A human carries out the goal <b><em>Drink</em> without expecting any assistance</b>. Tiago++ observes the situation, infers the human’s goal, and reasons about which tasks it could potentially support based on its own skills. 
                Despite this capability, the human completes all steps independently, as no collaboration is anticipated.
            </p>
        </div>

        <div class="video-item">
            <iframe 
                src="https://www.youtube.com/embed/dQw4w9WgXcQ" 
                title="Video 1"
                allowfullscreen>
            </iframe>
            <p class="caption">
                A human carries out the goal <b><em>Breakfast</em> without expecting any assistance</b>. Tiago++ observes the situation, infers the human’s goal, and reasons about which tasks it could potentially support based on its own skills. 
                Despite this capability, the human completes all steps independently, as no collaboration is anticipated.
            </p>
        </div>

        <div class="video-item">
            <iframe 
                src="https://www.youtube.com/embed/dQw4w9WgXcQ" 
                title="Video 1"
                allowfullscreen>
            </iframe>
            <p class="caption">
                A human begins working toward the goal <b><em>Lunch</em>, expecting assistance</b>. Tiago++ observes the scene, infers the human’s intention, and reasons about how it can contribute based on its own capabilities.
                The human completes part of the task and leaves the remaining steps to the robot, anticipating collaboration. Tiago++ waits until the human has finished their portion, remains ready to act, and clearly communicates which parts of the goal it will execute when it is time to assist.
            </p>
        </div>

        <div class="video-item">
            <iframe 
                src="https://www.youtube.com/embed/dQw4w9WgXcQ" 
                title="Video 1"
                allowfullscreen>
            </iframe>
            <p class="caption">
                A human begins working toward the goal <b><em>Drink</em>, expecting assistance</b>. Tiago++ observes the scene, infers the human’s intention, and reasons about how it can contribute based on its own capabilities.
        The human completes part of the task and leaves the remaining steps to the robot, anticipating collaboration. Tiago++ waits until the human has finished their portion, remains ready to act, and clearly communicates which parts of the goal it will execute when it is time to assist.
            </p>
        </div>

        <div class="video-item">
            <iframe 
                src="https://www.youtube.com/embed/dQw4w9WgXcQ" 
                title="Video 1"
                allowfullscreen>
            </iframe>
            <p class="caption">
                A human begins working toward the goal <b><em>Breakfast</em>, expecting assistance</b>. Tiago++ observes the scene, infers the human’s intention, and reasons about how it can contribute based on its own capabilities.
        The human completes part of the task and leaves the remaining steps to the robot, anticipating collaboration. Tiago++ waits until the human has finished their portion, remains ready to act, and clearly communicates which parts of the goal it will execute when it is time to assist.
            </p>
        </div>

    </div>
</section>

<!-- GITHUB SECTION -->
<section id="github" class="section">
    <h2>GitHub</h2>
    <p>Check out our project repository:</p>

    <div class="github-links">
        <div class="github-item">
            <a href="https://github.com/samvinanzi/CASPER" target="_blank">
                <!-- GitHub SVG Icon -->
                <svg viewBox="0 0 24 24" class="svg-icon">
                    <path d="M12 .5C5.65.5.5 5.65.5 12c0 5.08 3.29 9.38 7.86 10.89.57.1.78-.25.78-.55v-2.12c-3.2.7-3.87-1.54-3.87-1.54-.52-1.31-1.27-1.66-1.27-1.66-1.04-.71.08-.7.08-.7 1.15.08 1.75 1.18 1.75 1.18 1.02 1.74 2.68 1.24 3.33.95.1-.73.4-1.24.73-1.52-2.56-.29-5.25-1.28-5.25-5.72 0-1.26.45-2.3 1.18-3.11-.12-.29-.51-1.44.11-3 0 0 .96-.31 3.15 1.18a10.88 10.88 0 0 1 5.73 0c2.19-1.49 3.15-1.18 3.15-1.18.62 1.56.23 2.71.11 3 0 .01.01.02.01.03.73.81 1.18 1.85 1.18 3.11 0 4.44-2.69 5.42-5.26 5.71.41.36.77 1.08.77 2.17v3.22c0 .3.21.65.79.54A11.5 11.5 0 0 0 23.5 12c0-6.35-5.15-11.5-11.5-11.5z"/>
                </svg>
                <span>Project Repository</span>
            </a>
        </div>
    </div>
</section>

<section id="github" class="section">
    <h2>Funding</h2>
    <p>This material is based upon work supported by the Air Force Office of Scientific Research, Air Force Materiel Command, USA. Funder award no. FA8655-24-1-7047.</p>
</section>


<footer>
    © 2025 CASPER++ — All rights reserved.
</footer>


</body>
</html>
